{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwTyly1qnxxi",
        "outputId": "cda9b73a-339a-4fdb-e25a-ccd7f74f1bef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DixhWmqWcy3M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Mehq_mVQ59mk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYBZ86dRc2bq",
        "outputId": "47479a2c-b6bf-4231-ff92-9febbfdbde47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
      ],
      "metadata": {
        "id": "BYwLmovB5q4u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify GPU\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL27mL0_sTC",
        "outputId": "316ccb33-6e22-4840-d12b-347a840f48f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert to DataFrame for EDA"
      ],
      "metadata": {
        "id": "qyMy7PgZ_mME"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PBwbw0ddKYcJ"
      },
      "outputs": [],
      "source": [
        "def convert_data(filepath):\n",
        "\n",
        "  # Read the data from the text file\n",
        "  with open(filepath, \"r\") as file:\n",
        "      lines = file.readlines()\n",
        "\n",
        "  # Define an empty list to store the data\n",
        "  data = []\n",
        "\n",
        "  # Iterate over each line in the file\n",
        "  for line in lines:\n",
        "      # Split the line by spaces\n",
        "      parts = line.strip().split()\n",
        "\n",
        "      # Check if the line has the expected number of elements\n",
        "      if len(parts) == 9:\n",
        "          # Extract the values from the line\n",
        "          text_file_name = parts[0]\n",
        "          sentence_line_number = int(parts[1])\n",
        "          sentence_word_index = int(parts[2])\n",
        "          sentence_seq = parts[3]\n",
        "          start_token = int(parts[4])\n",
        "          end_token = int(parts[5])\n",
        "          original_word = parts[6]\n",
        "          word = parts[7]\n",
        "          label = parts[8]\n",
        "\n",
        "          # Append the values as a tuple to the data list\n",
        "          data.append((text_file_name, sentence_line_number, sentence_word_index, sentence_seq,\n",
        "                      start_token, end_token, original_word, word, label))\n",
        "\n",
        "  # Create a DataFrame from the data list with appropriate column names\n",
        "  df = pd.DataFrame(data, columns=['text_file_name', 'sentence_line_number', 'sentence_word_index',\n",
        "                                  'sentence_seq', 'start_token', 'end_token', 'original_word',\n",
        "                                  'word', 'label'])\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"/content/drive/MyDrive/266_final/data/Original_text/dataset1_train.txt\"\n",
        "test_data_path = \"/content/drive/MyDrive/266_final/data/Original_text/dataset1_test.txt\"\n",
        "\n",
        "train = convert_data(train_data_path)\n",
        "test = convert_data(test_data_path)\n",
        "\n",
        "print(f\"Length of train: {len(train)}\")\n",
        "print(f\"Length of test: {len(test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97zEc_c_qYWJ",
        "outputId": "701aa209-4c13-44f6-83af-14855db404e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train: 895141\n",
            "Length of test: 585761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = train.copy()"
      ],
      "metadata": {
        "id": "ipR22Y9PrElo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentence_line_number'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqnvelmiGLXi",
        "outputId": "f42e598d-559a-4710-8016-38f36f647c5a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1053"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "E_JfdXDfoUMk",
        "outputId": "55aca176-e8ed-4e86-abf4-e34a4bfdeb9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      text_file_name  sentence_line_number  \\\n",
              "0  data/training_20180910/110727.txt                     1   \n",
              "1  data/training_20180910/110727.txt                     1   \n",
              "2  data/training_20180910/110727.txt                     1   \n",
              "3  data/training_20180910/110727.txt                     1   \n",
              "4  data/training_20180910/110727.txt                     1   \n",
              "\n",
              "   sentence_word_index sentence_seq  start_token  end_token original_word  \\\n",
              "0                    0           NA            0          9     Admission   \n",
              "1                    1           NA           10         14          Date   \n",
              "2                    2           NA           14         15             :   \n",
              "3                    3           NA           17         18             [   \n",
              "4                    4           NA           18         19             *   \n",
              "\n",
              "        word label  \n",
              "0  Admission     O  \n",
              "1       Date     O  \n",
              "2          :     O  \n",
              "3          [     O  \n",
              "4          *     O  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-356c0769-253d-4246-a576-29eb8e6db79f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_file_name</th>\n",
              "      <th>sentence_line_number</th>\n",
              "      <th>sentence_word_index</th>\n",
              "      <th>sentence_seq</th>\n",
              "      <th>start_token</th>\n",
              "      <th>end_token</th>\n",
              "      <th>original_word</th>\n",
              "      <th>word</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NA</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>Admission</td>\n",
              "      <td>Admission</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NA</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>Date</td>\n",
              "      <td>Date</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NA</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NA</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>[</td>\n",
              "      <td>[</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NA</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>*</td>\n",
              "      <td>*</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-356c0769-253d-4246-a576-29eb8e6db79f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-356c0769-253d-4246-a576-29eb8e6db79f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-356c0769-253d-4246-a576-29eb8e6db79f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a5809a1c-3bc2-4283-b11e-560cf28fd2ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5809a1c-3bc2-4283-b11e-560cf28fd2ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a5809a1c-3bc2-4283-b11e-560cf28fd2ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVvq1qgWw1vR",
        "outputId": "e31fb3d1-88b4-466d-e2c3-aaaf57a21994"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "O              802045\n",
              "B-Drug          16222\n",
              "I-Frequency     13023\n",
              "I-Dosage         8779\n",
              "B-Strength       6691\n",
              "B-Form           6647\n",
              "I-Strength       6617\n",
              "B-Frequency      6279\n",
              "B-Route          5475\n",
              "I-Drug           4298\n",
              "B-Dosage         4221\n",
              "I-Form           4173\n",
              "B-Reason         3791\n",
              "I-Reason         3125\n",
              "I-Duration       1034\n",
              "B-ADE             956\n",
              "I-ADE             776\n",
              "B-Duration        592\n",
              "I-Route           397\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['sentence_line_number'] == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "s1k_AqE-MHR0",
        "outputId": "2cba2ed9-1bb9-403a-f1ce-c81832b93e54"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           text_file_name  sentence_line_number  \\\n",
              "0       data/training_20180910/110727.txt                     1   \n",
              "1       data/training_20180910/110727.txt                     1   \n",
              "2       data/training_20180910/110727.txt                     1   \n",
              "3       data/training_20180910/110727.txt                     1   \n",
              "4       data/training_20180910/110727.txt                     1   \n",
              "...                                   ...                   ...   \n",
              "893314  data/training_20180910/100883.txt                     1   \n",
              "893315  data/training_20180910/100883.txt                     1   \n",
              "893316  data/training_20180910/100883.txt                     1   \n",
              "893317  data/training_20180910/100883.txt                     1   \n",
              "893318  data/training_20180910/100883.txt                     1   \n",
              "\n",
              "        sentence_word_index sentence_seq  start_token  end_token  \\\n",
              "0                         0           NA            0          9   \n",
              "1                         1           NA           10         14   \n",
              "2                         2           NA           14         15   \n",
              "3                         3           NA           17         18   \n",
              "4                         4           NA           18         19   \n",
              "...                     ...          ...          ...        ...   \n",
              "893314                   23           NA           64         65   \n",
              "893315                   24           NA           65         66   \n",
              "893316                   25           NA           66         67   \n",
              "893317                   26           NA           67         68   \n",
              "893318                   27           NA           68         69   \n",
              "\n",
              "       original_word       word label  \n",
              "0          Admission  Admission     O  \n",
              "1               Date       Date     O  \n",
              "2                  :          :     O  \n",
              "3                  [          [     O  \n",
              "4                  *          *     O  \n",
              "...              ...        ...   ...  \n",
              "893314             -          -     O  \n",
              "893315             3    ORDINAL     O  \n",
              "893316             *          *     O  \n",
              "893317             *          *     O  \n",
              "893318             ]          ]     O  \n",
              "\n",
              "[8547 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db99a1b4-1b57-4961-8acc-a12eb762c0af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_file_name</th>\n",
              "      <th>sentence_line_number</th>\n",
              "      <th>sentence_word_index</th>\n",
              "      <th>sentence_seq</th>\n",
              "      <th>start_token</th>\n",
              "      <th>end_token</th>\n",
              "      <th>original_word</th>\n",
              "      <th>word</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NA</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>Admission</td>\n",
              "      <td>Admission</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NA</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>Date</td>\n",
              "      <td>Date</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NA</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NA</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>[</td>\n",
              "      <td>[</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data/training_20180910/110727.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NA</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>*</td>\n",
              "      <td>*</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893314</th>\n",
              "      <td>data/training_20180910/100883.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>NA</td>\n",
              "      <td>64</td>\n",
              "      <td>65</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893315</th>\n",
              "      <td>data/training_20180910/100883.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>NA</td>\n",
              "      <td>65</td>\n",
              "      <td>66</td>\n",
              "      <td>3</td>\n",
              "      <td>ORDINAL</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893316</th>\n",
              "      <td>data/training_20180910/100883.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>NA</td>\n",
              "      <td>66</td>\n",
              "      <td>67</td>\n",
              "      <td>*</td>\n",
              "      <td>*</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893317</th>\n",
              "      <td>data/training_20180910/100883.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>NA</td>\n",
              "      <td>67</td>\n",
              "      <td>68</td>\n",
              "      <td>*</td>\n",
              "      <td>*</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893318</th>\n",
              "      <td>data/training_20180910/100883.txt</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>NA</td>\n",
              "      <td>68</td>\n",
              "      <td>69</td>\n",
              "      <td>]</td>\n",
              "      <td>]</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8547 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db99a1b4-1b57-4961-8acc-a12eb762c0af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db99a1b4-1b57-4961-8acc-a12eb762c0af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db99a1b4-1b57-4961-8acc-a12eb762c0af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da3ae54b-7db4-4953-8b91-0e9883710999\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da3ae54b-7db4-4953-8b91-0e9883710999')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da3ae54b-7db4-4953-8b91-0e9883710999 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[df['sentence_line_number'] == 1]\",\n  \"rows\": 8547,\n  \"fields\": [\n    {\n      \"column\": \"text_file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 303,\n        \"samples\": [\n          \"data/training_20180910/125867.txt\",\n          \"data/training_20180910/102173.txt\",\n          \"data/training_20180910/186876.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_line_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_word_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 32,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_seq\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"NA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 0,\n        \"max\": 119,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 4,\n        \"max\": 120,\n        \"num_unique_values\": 105,\n        \"samples\": [\n          61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_word\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 177,\n        \"samples\": [\n          \"12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"Admission\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label labels"
      ],
      "metadata": {
        "id": "GWzDzNtXJRSa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXnnrZqSIX95",
        "outputId": "c5022c4a-6c7a-4133-a83b-7b5c2bd26795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I-Reason', 'I-Frequency', 'I-Drug', 'I-Strength', 'B-Strength', 'B-Duration', 'B-Drug', 'B-ADE', 'B-Route', 'B-Dosage', 'I-Form', 'I-Route', 'B-Reason', 'I-ADE', 'I-Duration', 'I-Dosage', 'B-Form', 'B-Frequency', 'O'}\n"
          ]
        }
      ],
      "source": [
        "# Split labels based on whitespace and turn them into a list\n",
        "labels = [i.split() for i in df['label'].values.tolist()]\n",
        "\n",
        "# Check how many labels are there in the dataset\n",
        "unique_labels = set()\n",
        "\n",
        "for lb in labels:\n",
        "  [unique_labels.add(i) for i in lb if i not in unique_labels]\n",
        "\n",
        "print(unique_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eMSm91uh8hHU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux83z2FGLU05",
        "outputId": "657142a0-8729-4599-aa4c-d4ac2def63be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-ADE': 0, 'B-Dosage': 1, 'B-Drug': 2, 'B-Duration': 3, 'B-Form': 4, 'B-Frequency': 5, 'B-Reason': 6, 'B-Route': 7, 'B-Strength': 8, 'I-ADE': 9, 'I-Dosage': 10, 'I-Drug': 11, 'I-Duration': 12, 'I-Form': 13, 'I-Frequency': 14, 'I-Reason': 15, 'I-Route': 16, 'I-Strength': 17, 'O': 18}\n"
          ]
        }
      ],
      "source": [
        "# Map each label into its id representation and vice versa\n",
        "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
        "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n",
        "print(labels_to_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatted_df_cl(df):\n",
        "  df['sentence'] = df[[\n",
        "      'text_file_name',\n",
        "      'original_word',\n",
        "      'label']].groupby(\n",
        "          ['text_file_name'])['original_word'].transform(lambda x: ' '.join(x))\n",
        "\n",
        "  df['word_labels'] = df[[\n",
        "      'text_file_name',\n",
        "      'original_word',\n",
        "      'label']].groupby(\n",
        "          ['text_file_name'])['label'].transform(lambda x: ','.join(x))\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "AY-2vTLnodGd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = formatted_df_cl(df)\n",
        "test = formatted_df_cl(test)"
      ],
      "metadata": {
        "id": "qNJIWjL1sGg9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkb2_rCOxPhB",
        "outputId": "61afbb40-0c96-44a5-9276-8aa6b8bbae68"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text_file_name                          data/training_20180910/110727.txt\n",
              "sentence_line_number                                                    1\n",
              "sentence_word_index                                                     0\n",
              "sentence_seq                                                           NA\n",
              "start_token                                                             0\n",
              "end_token                                                               9\n",
              "original_word                                                   Admission\n",
              "word                                                            Admission\n",
              "label                                                                   O\n",
              "sentence                Admission Date : [ * * 2202 - 1 - 8 * * ] Disc...\n",
              "word_labels             O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_level_data(df):\n",
        "  sentence_level_data = df[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
        "  return sentence_level_data"
      ],
      "metadata": {
        "id": "l3zrCBf-sfe-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence_level_data = df[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
        "# sentence_level_data.head()"
      ],
      "metadata": {
        "id": "XpGwter59c47"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_level_train = sentence_level_data(df)\n",
        "sentence_level_test = sentence_level_data(test)"
      ],
      "metadata": {
        "id": "O2f8oq0fssJd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_level_train.iloc[85].sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "NfcU3rIg-x94",
        "outputId": "ea7779a5-b600-45b7-9d8d-f2015c2c3583"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_level_train.iloc[85].word_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "hyBQMf9x-lcM",
        "outputId": "834fe3ee-0e67-4ce5-c04f-dbf0fe9be68e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,B-Drug,O,B-Drug,O,O,O,O,B-Drug,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Strength,I-Strength,B-Drug,O,B-Strength,I-Strength,B-Drug,O,B-Strength,I-Strength,B-Route,B-Drug,O,B-Strength,I-Strength,B-Route,B-Drug,O,B-Drug,B-Strength,I-Strength,B-Route,O,B-Dosage,O,B-Drug,B-Strength,I-Strength,B-Route,O,O,O,O,O,O,O,O,B-ADE,O,B-ADE,I-ADE,O,O,O,O,B-Drug,O,B-Drug,O,O,O,O,B-Strength,I-Strength,B-Route,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,B-Frequency,B-Duration,I-Duration,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,B-Drug,B-Route,B-Frequency,O,O,O,O,B-ADE,O,O,O,O,O,O,B-ADE,I-ADE,O,O,O,O,B-Drug,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,B-Drug,O,O,B-Drug,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,B-Frequency,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Frequency,B-Drug,B-Drug,B-Frequency,I-Frequency,I-Frequency,B-Drug,B-Strength,I-Strength,O,B-Frequency,B-Drug,B-Drug,B-Frequency,O,O,O,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,I-Drug,B-Strength,O,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,I-Drug,B-Strength,O,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,O,O,O,O,O,O,O,O,B-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,O,O,B-Drug,I-Drug,I-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,I-Form,I-Form,I-Form,I-Form,I-Form,I-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,I-Form,I-Form,I-Form,I-Form,I-Form,I-Form,B-Route,B-Frequency,O,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,I-Drug,B-Strength,O,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,I-Drug,B-Strength,O,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,O,O,O,O,O,O,O,O,B-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,O,O,B-Drug,I-Drug,I-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,I-Form,I-Form,I-Form,I-Form,I-Form,I-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,I-Form,I-Form,I-Form,I-Form,I-Form,I-Form,B-Route,B-Frequency,O,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,I-Drug,B-Strength,I-Strength,I-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,O,O,O,O,O,B-Duration,I-Duration,I-Duration,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,I-Drug,B-Strength,I-Strength,B-Form,I-Form,I-Form,I-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,I-Form,I-Form,I-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,B-Duration,I-Duration,I-Duration,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = sentence_level_train.copy()\n",
        "data_test = sentence_level_test.copy()"
      ],
      "metadata": {
        "id": "745qa3MhQpM7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T-NdnbvtFcKI",
        "outputId": "b0cc277d-d0b9-41e5-b40a-028a5be31b16"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  Admission Date : [ * * 2202 - 1 - 8 * * ] Disc...   \n",
              "1  Admission Date : [ * * 2130 - 10 - 2 * * ] Dis...   \n",
              "2  Admission Date : [ * * 2151 - 1 - 25 * * ] Dis...   \n",
              "3  Admission Date : [ * * 2193 - 12 - 23 * * ] Di...   \n",
              "4  Admission Date : [ * * 2133 - 3 - 28 * * ] Dis...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "3  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "4  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d28039b0-aad0-45a2-ba5c-fd9cc8953c39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Admission Date : [ * * 2202 - 1 - 8 * * ] Disc...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Admission Date : [ * * 2130 - 10 - 2 * * ] Dis...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Admission Date : [ * * 2151 - 1 - 25 * * ] Dis...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Admission Date : [ * * 2193 - 12 - 23 * * ] Di...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Admission Date : [ * * 2133 - 3 - 28 * * ] Dis...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d28039b0-aad0-45a2-ba5c-fd9cc8953c39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d28039b0-aad0-45a2-ba5c-fd9cc8953c39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d28039b0-aad0-45a2-ba5c-fd9cc8953c39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-341f78bb-ae53-4640-afb6-fff7fdc9283c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-341f78bb-ae53-4640-afb6-fff7fdc9283c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-341f78bb-ae53-4640-afb6-fff7fdc9283c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_train",
              "summary": "{\n  \"name\": \"data_train\",\n  \"rows\": 303,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 303,\n        \"samples\": [\n          \"Name : [ * * Known lastname * * ] , [ * * Known firstname 9188 * * ] Unit No : [ * * Numeric Identifier 15402 * * ] Admission Date : [ * * 2107 - 3 - 4 * * ] Discharge Date : [ * * 2107 - 3 - 10 * * ] Date of Birth : [ * * 2029 - 12 - 14 * * ] Sex : F Service : FINAL DISCHARGE MEDICATIONS : 1 . Heparin 5 , 000 units subq q.8 . 2 . Acetaminophen 325 mg 1 - 2 tablets p.o . q.4 - 6h . prn . 3 . Olanzapin e 2.5 mg p.o . q.i.d . prn . 4 . Docusate 100 mg p.o . b.i.d . prn . 5 . Senna 8.6 mg p.o . b.i.d . prn . 6 . Carbidopa/ levodopa 25/100 mg one tablet p.o . t.i.d . 7 . Levothyroxine 100 mcg p.o . q.d . 8 . Valsartan/ hydrochlorothiazide 80/12.5 mg one tablet p.o . q.d . FOLLOW - UP PLANS : Patient has follow up with neurologist on [ * * 2107 - 4 - 25 * * ] at 12 p.m . Patient will need outpatient psychiatric followup , which can be arranged by the rehab facility or the patient's PCP . [ * * Name10 ( NameIs ) 15403 * * ] patient will likely need close followup of thyroid replacement medication as she will likely require a lower dose of exogenous thyroid in the future as she is unlikely to be reinstated on Lithium therapy . [ * * First Name11 ( Name Pattern1 ) 499 * * ] [ * * Last Name ( NamePattern4 ) 2839 * * ] , M.D . [ * * MD Number ( 1 ) 2840 * * ] Dictated By : [ * * Last Name ( NamePattern1 ) 9981 * * ] MEDQUIST36 D : [ * * 2107 - 3 - 10 * * ] 15 : 04 T : [ * * 2107 - 3 - 11 * * ] 04 : 24 JOB # : [ * * Job Number 15404 * * ]\",\n          \"Admission Date : [ * * 2176 - 7 - 5 * * ] Discharge Date : [ * * 2176 - 7 - 7 * * ] Service : SURGERY Allergies : Amoxicillin / Penicillins / Coumadin / Oxycodone / Megestrol Acetate / Remeron / Ritalin Attending : [ * * First Name3 ( LF ) 301 * * ] Chief Complaint : Free air on CXR Major Surgical or Invasive Procedure : None History of Present Illness : Pt is a 87 y/o male with extensive past medical history who was recently discharged after admission for possible meningitis/altered mental status . During that admission the patient was found to be a significant aspiration risk and a G - tube was placed by interventional radiology . He was discharged to [ * * Hospital * * ] rehab in good condition off all antibiotics on [ * * 7 - 4 * * ] . He presents today after a routine CXR was performed at [ * * Hospital * * ] rehab which demonstrated free intra - abdominal air beneath the right hemidiaphragm . The patient was subsequently transfered to [ * * Hospital1 18 * * ] for evaluation . At the time of presentation he was in no acute distress , without complaints of pain , nausea/vomiting , fever/chills . He had a suprapubic catheter which was functioning appropriately as well as a flexi - seal rectal tube which was collecting appropriate volumes of stool . Past Medical History : - DM II , on insulin - prostate CA s/p XRT [ * * 2156 * * ] - chronic urinary incontinence , s/p TURP [ * * 10 - 6 * * ] - history of UTIs , including prior MRSA , klebsiella , proteus , pseuduomonas - s/p bladder rupture and repair x2 , [ * * 2 - 8 * * ] , [ * * 6 - 8 * * ] - atrial fibrillation , not anticoagulated due to h/o bleeding - hyperthyroidism - depression - hypertension - moderate aortic stenosis on TTE [ * * 5 - /2176 * * ] - peripheral vascular disease - h/o CVA [ * * 2172 * * ] - severe chronic axonal neuropathy , radiculopathy and plexopathy ( due to XRT ) per Dr . [ * * Last Name ( STitle ) * * ] , with right foot drop for many years - L3 compression fracture - cataract s/p bilateral laser surgery , also with \\\"macular edema\\\" s/p dexamethasone injection - hard of hearing - left thyroid nodule , benign Social History : Smoked 2 ppd tobacco x24 years . Quit in [ * * 2137 * * ] . Denies EtOH . Former WWII vet . Former Fire Fighter . Wife is HCP . Daughter is RN , son is engineer . Family History : No illnesses , strokes , DM or early heart attacks run in the family . Physical Exam : On Admission GEN : NAD HEENT : AT/NC , EOMI , neck supple , trachea midline CV : Irregular , no m/g/r RESP : CTAB ABD : soft , non - tender , non - distended , no rebound , no guarding , no external evidence of injury , no gross masses , midline infra - umbilical incision well healed . L midline ; G - tube secured , no surrounding erythema or discharge . Suprapubic catheter , secured , no discharge/erythema . Rectal tube in place EXT : no C/C/E TLD : R PICC Pertinent Results : [ * * 2176 - 7 - 4 * * ] 05 : 55AM BLOOD WBC - 5.8 RBC - 2.50 * Hgb - 7.5 * Hct - 23.8 * MCV - 95 MCH - 29.8 MCHC - 31.3 RDW - 17.1 * Plt Ct - 396 [ * * 2176 - 7 - 4 * * ] 05 : 55AM BLOOD Plt Ct - 396 [ * * 2176 - 7 - 4 * * ] 05 : 55AM BLOOD Glucose - 116 * UreaN - 31 * Creat - 1.7 * Na - 147 * K - 4.3 Cl - 118 * HCO3 - 23 AnGap - 10 [ * * 2176 - 7 - 4 * * ] 05 : 55AM BLOOD Calcium - 8.0 * Phos - 2.5 * Mg - 2.2 Radiology Report CHEST ( PA & LAT ) Study Date of [ * * 2176 - 7 - 5 * * ] 2 : 22 PM FINDINGS : Comparison made to 5/28/200 , and to fluoroscopy from GJ tube placement [ * * 2176 - 7 - 3 * * ] . Free intraperitoneal air under both hemidiaphragms is not unexpected following recent G - tube placement . Cardiomediastinal contours are unchanged . The lungs are grossly clear and well expanded . Right PICC terminates in the mid SVC . There is no pleural effusion or pneumothorax . Radiology Report CHEST ( PA & LAT ) Study Date of [ * * 2176 - 7 - 6 * * ] 2 : 22 PM FINDINGS : There is a moderate amount of free air seen under the right hemidiaphragm extending across the midline . The amount on the right is similar compared to prior . The amount on the left is slightly less . _____ tube is again seen over the left upper quadrant . There is patchy atelectasis in the left lower lung . The right subclavian PICC line is unchanged . Brief Hospital Course : Pt admitted to observation due to free air seen on CXR s/p PEG placement . Abdominal exam benign during hospital course . Free air stable on serial CXR . Tube feeds via g - tube resumed and advanced and tolerated well . Pt discharged back to rehab facility [ * * 2172 - 7 - 5 * * ] . Medications on Admission : 1 . Phenytoin 125 mg/5 mL Suspension Sig : One ( 1 ) PO TID ( 3 times a day ) . 2 . Metoprolol Tartrate 25 mg Tablet Sig : One ( 1 ) Tablet PO BID ( 2 times a day ) . 3 . Acetaminophen 325 mg Tablet Sig : 1 - 2 Tablets PO Q6H ( every 6 hours ) as needed for pain . 4 . Miconazole Nitrate 2 % Powder Sig : One ( 1 ) Appl Topical [ * * Hospital1 * * ] ( 2 times a day ) as needed for rash . 5 . Senna 8.6 mg Tablet Sig : One ( 1 ) Tablet PO BID ( 2 times a day ) as needed for constipation . 6 . Docusate Sodium 50 mg/5 mL Liquid Sig : Ten ( 10 ) mL PO BID ( 2 times a day ) . 7 . Insulin Glargine 100 unit/mL Cartridge Sig : Six ( 6 ) Units Subcutaneous at bedtime . 8 . Heparin ( Porcine ) 5 , 000 unit/mL Solution Sig : One ( 1 ) mL Injection TID ( 3 times a day ) . 9 . Aspirin 81 mg Tablet Sig : One ( 1 ) Tablet PO once a day . Discharge Medications : 1 . Phenytoin 125 mg/5 mL Suspension Sig : One [ * * Age over 90 * * ]y Five ( 125 ) mg PO TID ( 3 times a day ) . 2 . Metoprolol Tartrate 25 mg Tablet Sig : One ( 1 ) Tablet PO BID ( 2 times a day ) . 3 . Acetaminophen 325 mg Tablet Sig : 1 - 2 Tablets PO Q6H ( every 6 hours ) as needed for pain . 4 . Miconazole Nitrate 2 % Cream Sig : One ( 1 ) Appl Topical [ * * Hospital1 * * ] ( 2 times a day ) as needed for fungus . 5 . Senna 8.6 mg Tablet Sig : One ( 1 ) Tablet PO HS ( at bedtime ) . 6 . Colace 50 mg/5 mL Liquid Sig : One Hundred ( 100 ) mg PO twice a day as needed for constipation . 7 . Lantus 100 unit/mL Solution Sig : Six ( 6 ) Units Subcutaneous at bedtime . 8 . Aspirin 81 mg Tablet , Chewable Sig : One ( 1 ) Tablet , Chewable PO DAILY ( Daily ) . 9 . Heparin ( Porcine ) 5 , 000 unit/mL Solution Sig : 5000 ( 5000 ) units SC Injection TID ( 3 times a day ) . 10 . Heparin , Porcine ( PF ) 10 unit/mL Syringe Sig : Two ( 2 ) ML Intravenous PRN ( as needed ) as needed for line flush . Discharge Disposition : Extended Care Facility : [ * * Hospital6 459 * * ] for the Aged - LTC Discharge Diagnosis : Free air on CXR s/p G - tube placement Discharge Condition : Good Discharge Instructions : Please call your surgeon if you develop chest pain , shortness of breath , fever greater than 101.5 , severe abdominal pain or distention , persistent nausea or vomiting , inability to eat or drink , or any other symptoms which are concerning to you . Activity : No heavy lifting of items [ * * 11 - 14 * * ] pounds until the follow up appointment with your doctor . Medications : Resume your home medications . You should take a stool softener , Colace 100 mg twice daily as needed for constipation . Pain medication may make you drowsy . No driving while taking pain medicine . Followup Instructions : Provider : [ * * First Name11 ( Name Pattern1 ) * * ] [ * * Last Name ( NamePattern4 ) 7025 * * ] , MD Phone : [ * * Telephone/Fax ( 1 ) 5285 * * ] Date/Time : [ * * 2176 - 8 - 8 * * ] 10 : 00 Provider : [ * * First Name11 ( Name Pattern1 ) * * ] [ * * Last Name ( NamePattern1 ) * * ] , MD Phone : [ * * Telephone/Fax ( 1 ) 435 * * ] Date/Time : [ * * 2176 - 8 - 9 * * ] 11 : 00 Please call the office of Dr.[ * * Last Name ( STitle ) * * ] at ( [ * * Telephone/Fax ( 1 ) 9000 * * ] to schedule a follow - up appointment .\",\n          \"Admission Date : [ * * 2152 - 7 - 25 * * ] Discharge Date : [ * * 2152 - 8 - 2 * * ] Service : MEDICINE Allergies : Levofloxacin / Nitrofurantoin / Sulfa ( Sulfonamide Antibiotics ) / Penicillins / NSAIDS ( Non - Steroidal Anti - Inflammatory Drug ) / lansoprazole / Tomato / Celery / Egg White / Beef Containing Products / Strawberry / Potato Starch / peppers / oranges Attending : [ * * First Name3 ( LF ) 2782 * * ] Chief Complaint : respiratory disress Major Surgical or Invasive Procedure : none History of Present Illness : Ms . [ * * Known lastname * * ] is a [ * * Age over 90 * * ] yo lady with a history of COPD , CHF , alzheimer's and expressive aphasia , who presented from her nursing home to the ED in respiratory distress on [ * * 2152 - 7 - 26 * * ] about 1.5 hours after eating her lunch . She has had an episode of aspiration about one year ago as well as urosepsis a few months ago . In the ED , her vitals were T 98.9F , HR 130 , BP 158/66 , RR 40 and O2 sat of 91 % on RL . A chest xray taken showed widespread coarse reticular opacities but no signs of consolidation . She was given solumedrol given her history of COPD . She was also started on IV Vancomycine and Aztreonam ( due to a PCN allergy ) as well as metronidazole . She was also given 1L Normal Saline for alactate of 4.7 . EKG showed sinus tachycardia . She was then admitted to the MICU for further care . In the MICU , her Aztreonam was dc'ed , and she was started on cefepime instead . She was also started on an insulin sliding scale . Her lactate returned to 1.3 , and her cre and WBC trended down as well ( WBC 26 ) . Her IV fluids were tricky since any flow >75cc/hr led to hypertension with sbp int he 170's . However , she was able to tolerate small boluses of fluids . A straight cath performed also showed purulent liquid , though her urine cultures from [ * * 2152 - 7 - 25 * * ] were negative . After a few hours in the MICU , she was transferred to the floor . Review of systems : Limited by patient's mental status Past Medical History : - alzheimers - expressive aphasia - dysphagia - aspiration pneumonia in past - colon CA - asthma/COPD - osteoporosis - lumbar laminectomy - UTI - anemia - DM - CHF ( EF : 67 % in [ * * 2142 * * ] ) - Hx of MI ( last known in [ * * 2148 * * ] ) Social History : Nursing home resident Per her son , she was a 40 pack year smoker . No current Etoh or drugs . Has 3 children , including a son who is a dermatologist at [ * * Hospital1 * * ] , who are all very involved in her care . Family History : Non - contributory Physical Exam : Admission Exam : General : Pt appeared uncomfortable , laying in bed . Pulm : tachypnic , shallow somewhat labored breaths . diffuse coarse crackles heard throughout , bilaterally . Some bronchial sounds at the apex bilaterally along with mild wheezes . Discharge Exam VS : 98.2 , 130 - 160/58 - 100 , 18 - 24 , 95 % on RA General : Frail elderly woman resting comfortably in no acute distress HEENT : Right eyelid closed intermittently . Sclera anicteric , nasal canula in place Neck : supple , moist CV : regular , no longer tachycardic . Lungs : Coarse crackles along leftlung base . Otherwise , clear ( much improved since admission ) . Mildly tachypneic with somewhat shallow breathing and occasional use of accessory muscles when alert . Not when sleeping . Abdomen : soft , non - tender , non - distended , bowel sounds present , no organomegaly GU : no foley ( d/c'ed on [ * * 2152 - 7 - 29 * * ] ) Ext : warm , well perfused , 2+ pulses , no clubbing , cyanosis or edema . lower extremities contracted Neuro : CNII - XII grossly intact , extremities contracted Pertinent Results : Labs on Admission : [ * * 2152 - 7 - 25 * * ] 09 : 10PM LACTATE - 4.3 * [ * * 2152 - 7 - 25 * * ] 08 : 22PM URINE COLOR - Straw APPEAR - Hazy SP [ * * Last Name ( un ) 155 * * ] - 1.008 [ * * 2152 - 7 - 25 * * ] 08 : 22PM URINE BLOOD - MOD NITRITE - NEG PROTEIN - 30 GLUCOSE - 1000 KETONE - NEG BILIRUBIN - NEG UROBILNGN - NEG PH - 7.0 LEUK - LG [ * * 2152 - 7 - 25 * * ] 08 : 22PM URINE RBC - 59 * WBC - >182 * BACTERIA - MOD YEAST - NONE EPI - 0 [ * * 2152 - 7 - 25 * * ] 08 : 22PM URINE MUCOUS - RARE [ * * 2152 - 7 - 25 * * ] 03 : 20PM LACTATE - 4.7 * [ * * 2152 - 7 - 25 * * ] 03 : 00PM GLUCOSE - 248 * UREA N - 29 * CREAT - 0.9 SODIUM - 131 * POTASSIUM - 4.8 CHLORIDE - 93 * TOTAL CO2 - 24 ANION GAP - 19 [ * * 2152 - 7 - 25 * * ] 03 : 00PM estGFR - Using this [ * * 2152 - 7 - 25 * * ] 03 : 00PM cTropnT - 0.01 [ * * 2152 - 7 - 25 * * ] 03 : 00PM WBC - 12.8 * RBC - 4.46 HGB - 12.0 HCT - 38.4 MCV - 86 MCH - 26.9 * MCHC - 31.2 RDW - 14.9 [ * * 2152 - 7 - 25 * * ] 03 : 00PM NEUTS - 83.2 * LYMPHS - 12.0 * MONOS - 1.9 * EOS - 2.6 BASOS - 0.4 [ * * 2152 - 7 - 25 * * ] 03 : 00PM PLT COUNT - 427 [ * * 2152 - 7 - 25 * * ] 03 : 00PM PT - 11.5 PTT - 28.2 INR ( PT ) - 1.1 Labs on Medicine floor : [ * * 2152 - 8 - 1 * * ] 07 : 30AM BLOOD WBC - 6.5 RBC - 3.80 * Hgb - 10.4 * Hct - 33.2 * MCV - 87 MCH - 27.4 MCHC - 31.3 RDW - 15.5 Plt Ct - 347 [ * * 2152 - 8 - 1 * * ] 07 : 30AM BLOOD Glucose - 106 * UreaN - 11 Creat - 0.7 Na - 141 K - 3.2 * Cl - 108 HCO3 - 23 AnGap - 13 [ * * 2152 - 8 - 1 * * ] 07 : 30AM BLOOD Calcium - 8.4 Phos - 2.2 * Mg - 1.7 [ * * 2152 - 7 - 31 * * ] 07 : 10PM BLOOD Lactate - 1.1 [ * * 2152 - 7 - 28 * * ] 04 : 40PM BLOOD CK ( CPK ) - 36 [ * * 2152 - 7 - 28 * * ] 07 : 50AM BLOOD CK ( CPK ) - 36 [ * * 2152 - 7 - 28 * * ] 04 : 40PM BLOOD CK - MB - 3 cTropnT - 0.06 * [ * * 2152 - 7 - 28 * * ] 07 : 50AM BLOOD CK - MB - 3 cTropnT - 0.06 * [ * * 2152 - 7 - 25 * * ] 03 : 00PM BLOOD cTropnT - 0.01 CXR ( [ * * 7 - 28 * * ] ) : FINDINGS : In comparison with study of [ * * 7 - 25 * * ] , the diffuse bilateral pulmonary opacifications are less prominent . Some of this may reflect the PA rather than AP frontal view . Blunting of the costophrenic angles is consistent with bilateral pleural effusions with some compressive atelectasis at the bases . CXR ( [ * * 7 - 25 * * ] ) : FINDINGS : As compared to the previous radiograph , there is a mild increase in the diameter of the pulmonary vessels , potentially indicative of mild fluid overload . In addition , the atelectasis at the left lung base has increased in extent and there is blunting of the left costophrenic sinus , potentially caused by a small left pleural effusion . No cardiomegaly . Unchanged tortuosity of the thoracic aorta . No pneumothorax . EKG : [ * * 2152 - 6 - 30 * * ] : Sinus rhythm and occasional atrial ectopy . Low limb lead voltage . Prior anteroseptal myocardial infarction . Compared to the previous tracing of [ * * 2152 - 7 - 26 * * ] the axis is more rightward , atrial ectopy has appeared . Otherwise , no diagnostic interim change . MICRO : MRSA SCREEN ( Final [ * * 2152 - 7 - 27 * * ] ) : POSITIVE FOR METHICILLIN RESISTANT STAPH AUREUS Urine Cx , Blood Cx - negative Discharge Labs : [ * * 2152 - 8 - 1 * * ] 07 : 30AM BLOOD WBC - 6.5 RBC - 3.80 * Hgb - 10.4 * Hct - 33.2 * MCV - 87 MCH - 27.4 MCHC - 31.3 RDW - 15.5 Plt Ct - 347 [ * * 2152 - 8 - 2 * * ] 07 : 45AM BLOOD Na - 144 K - 4.0 Cl - 111 * [ * * 2152 - 8 - 1 * * ] 07 : 30AM BLOOD Calcium - 8.4 Phos - 2.2 * Mg - 1.7 Brief Hospital Course : Ms . [ * * Known lastname * * ] is a [ * * Age over 90 * * ]F with a history of COPD , alzheimer's dementia , and aspiration who presented from her nursing home in acute respiratory distress after eating lunch . SIRS 4 PROGRESS NOTE [ * * 2152 - 7 - 29 * * ] Assessment and Plan : Ms . [ * * Known lastname * * ] is a [ * * Age over 90 * * ]F with a history of COPD , alzheimer's dementia , and aspiration who presented from her nursing home in acute respiratory distress after eating lunch . # Respiratory Distress : Possibly secondary to aspiration , which is consistent with the presentation 1.5 hours after lunch . Initial CXR showed multiple reticular opacities but no consolidations . Repeat CXR showed less prominant bilateral opacifications , though there is possible bilateral pleural effusions with some compressed atelectasis at the bases . Initially on Vancomycin and Cefepime , switched to IV Ceftriaxone to treat UTI since pna was unlikely . IVF was at 40cc/ml for the last 3 days of her hospitalization . PO trial of thick liquids started on [ * * 2152 - 7 - 29 * * ] , which pt tolerated well . Lungs sounded a lot clearer with residual right base crackles . Pt breathing comfortably at 94 % O2 sat on room air . # Abnormal EKG - Admission EKG read yesterday by Cardiology , who was concerned about possible acute event . However , EKG compared with one in [ * * 2142 * * ] , which also showed similar changes . Troponins elevated at 0.06 x 2 but did not trend up , likely from transient ischemia due to increased cardiac demand [ * * 12 - 30 * * ] infection . No signs of acute cardiac event . Medical management with beta blocker , asa discussed with family , who declined due to allergy to asa and desire for minimal medication . Patient did tolerate beta - blocker ( metoprolol 6.25mg ) for one dose and seemed to perk up afterwards , but given difficulty in administration here in the hospital ( took patient an hour to swallow pill ) did not continue . Can be considered as outpatient . # Sepsis : Resolved . Likely secondary to a UTI . Grossly positive UA though urine culture was negative , PMH of recurrent UTIs , recent admission to [ * * Hospital3 * * ] with urosepsis from multi - drug resistant E.coli , necessitating treatment with primaxin . Straight cath in MICU drained purulent material . Urine culture showed no growth , but per pt's son , pt had already received IV abx at that time . Plan to complete 7 day course of ceftriaxone on [ * * 2152 - 8 - 3 * * ] . # Volume status : Tenuous . Per MICU and patient's son , patient become hypotensive with no fluids but rapidly becomes hypertensive ( up to sbp of 170's ) if fluids given too fast . At present appears to respond well to slow small fluid boluses , at a rate of 75 - 100cc/hr . Was continued on IVF at 40cc/hr per pts son as an amount that she has tolerated well in the past . # Diabetes Mellitus Type II : Started on ISS on [ * * 2152 - 7 - 26 * * ] , but NPO , became hypoglycemic and ISS was downtitrated in the MICU . Changed to regular insulin sliding . Glucose stable . Januvia held while inpatient and continued to use reduced dose insulin slididng scale . Can restart Januvia on d/c . # Sacral pressure ulcer : Wound care recs - Plan : Pressure redistribution measures , turn and reposition every 1 - 2 hrs off back . Limit sit time to 1 hr at time and sit on a pressure redist cushion . Protect intact skin midback and coccyx area with Critic aid Clear daily and prn or every 3rd cleansing . # Pruritus : pt developed agitated pruritus starting about 15 minutes after her cefepime infusion two days ago . Resolved on switch to ceftriaxone . # Hypokalemia : Resolved after repletion . # General - PT discontinued because it was too rigorous . Followed their initial recs of OOBx3 per day . . Transitional Issues - Encourage PO intake - Completion of ceftriaxone 1gm q24 hrs - last dose on [ * * 2152 - 8 - 3 * * ] - Consideration of maintenance fluids - Consider beta blocker ( per pt's family , pt seemed to perk up after single dose of metoprolol 6.25mg PO . Systolic BP decreased to 120's , HR in 70's , Respiration rate to 16 - 20 ) . Medications on Admission : Preadmission medications listed are correct and complete . Information was obtained from NH records . 1 . Januvia * NF * ( sitaGLIPtin ) 25 mg Oral daily 2 . Potassium Chloride 10 mEq PO DAILY Duration : 24 Hours Hold for K > 3 . Multivitamins 1 TAB PO DAILY 4 . Sodium Chloride Nasal 1 SPRY NU DAILY 5 . Acetaminophen 650 mg PO Q4H : PRN pain 6 . Bisacodyl 10 mg PR HS : PRN consitpation Discharge Medications : 1 . Bisacodyl 10 mg PR HS : PRN consitpation 2 . Acetaminophen 650 mg PO Q4H : PRN pain 3 . Januvia * NF * ( sitaGLIPtin ) 25 mg Oral daily 4 . Multivitamins 1 TAB PO DAILY 5 . Potassium Chloride 10 mEq PO DAILY Duration : 24 Hours Hold for K > 6 . Sodium Chloride Nasal 1 SPRY NU DAILY 7 . CeftriaXONE 1 gm IV Q24H Duration : 2 Doses Last day is [ * * 8 - 3 * * ] 8 . Docusate Sodium ( Liquid ) 100 mg PO BID 9 . Polyethylene Glycol 17 g PO DAILY : PRN constipation give this once now and then every other day if pt does not have a bowel movement every other day after that . 10 . Triamcinolone Acetonide 0.025 % Ointment 1 Appl TP DAILY rash please apply to rash on back once daily thin layer thx Discharge Disposition : Extended Care Facility : South Cover Manor Discharge Diagnosis : bacterial Urinary tract infection COPD Dementia NSTEMI Discharge Condition : Level of Consciousness : Alert and interactive . Activity Status : Bedbound . Mental Status : Confused - always . Discharge Instructions : Mrs [ * * Known lastname * * ] , you were admitted to [ * * Hospital1 18 * * ] due to concern for a respiratory infection . You were found to have a urine infection . A chest xray showed no evidence of a pneumonia , so we think its more likely that a urinary infection was causing your worsening status . You were given antibiotics and for a few days we didn't give you any food by mouth and gave it instead through your IV . When you had improved and were eating small amounts of food again , you were discharged back to [ * * Hospital3 * * ] . You will need 2 more days of ceftriaxone for your urinary infection Followup Instructions : You will be discharged back to [ * * Hospital3 * * ] and should continue care under your prior outpatient doctors . Completed by : [ * * 2152 - 8 - 3 * * ]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_labels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 303,\n        \"samples\": [\n          \"O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,I-Frequency,O,O,B-Drug,B-Strength,I-Strength,B-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,I-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Route,I-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,B-Drug,B-Strength,I-Strength,B-Route,I-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,B-Drug,B-Strength,I-Strength,B-Route,I-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Dosage,B-Form,B-Route,I-Route,B-Frequency,I-Frequency,O,O,B-Drug,B-Strength,I-Strength,B-Route,I-Route,B-Frequency,I-Frequency,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Dosage,B-Form,B-Route,I-Route,B-Frequency,I-Frequency,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,I-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O\",\n          \"O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,B-Drug,O,B-Drug,O,B-Drug,O,B-Drug,B-Drug,O,B-Drug,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Reason,I-Reason,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Route,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,I-Drug,O,O,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,O,O,O,O,O,O,O,O,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,I-Drug,B-Strength,I-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,I-Frequency,O,O,O,B-Drug,O,O,O,B-Strength,I-Strength,I-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,I-Strength,B-Form,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,I-Drug,O,O,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Reason,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,B-Route,B-Frequency,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,I-Frequency,O,O,O,B-Drug,B-Strength,I-Strength,B-Form,I-Form,I-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Form,I-Form,I-Form,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,O,B-Drug,I-Drug,I-Drug,I-Drug,B-Strength,I-Strength,I-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,I-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,O,O,B-Drug,I-Drug,I-Drug,I-Drug,I-Drug,I-Drug,B-Strength,I-Strength,B-Form,O,O,B-Dosage,I-Dosage,I-Dosage,I-Dosage,I-Dosage,B-Route,B-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,I-Reason,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Frequency,I-Frequency,I-Frequency,I-Frequency,O,B-Reason,O,B-Drug,I-Drug,O,O,O,B-ADE,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O\",\n          \"O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,B-Drug,O,B-Drug,O,O,O,O,O,B-Drug,O,B-Drug,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,B-Reason,O,O,O,O,O,O,B-Route,B-Drug,O,B-Drug,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,B-Dosage,B-Drug,I-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,B-Drug,B-Dosage,I-Dosage,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Route,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Dosage,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,B-Drug,O,O,O,B-Route,B-Drug,O,O,B-Reason,O,O,O,O,O,B-Drug,O,O,B-Strength,O,O,O,B-Duration,I-Duration,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,O,B-Drug,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Route,B-Drug,O,O,O,O,O,O,O,B-Duration,I-Duration,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Dosage,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,B-Strength,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Reason,I-Reason,I-Reason,I-Reason,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-ADE,O,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,B-Dosage,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,B-Drug,B-Dosage,I-Dosage,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-ADE,O,O,O,B-ADE,I-ADE,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,B-Frequency,I-Frequency,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,B-Strength,B-Route,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,O,O,O,B-Strength,I-Strength,B-Route,B-Frequency,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Route,B-Frequency,O,O,B-Duration,I-Duration,O,O,O,O,O,O,B-Drug,B-Dosage,B-Form,B-Route,B-Frequency,O,O,B-Drug,I-Drug,B-Form,B-Dosage,B-Form,B-Route,B-Frequency,O,O,B-Drug,B-Strength,I-Strength,B-Route,B-Frequency,I-Frequency,I-Frequency,B-Reason,O,O,B-Drug,B-Strength,I-Strength,B-Route,B-Frequency,I-Frequency,I-Frequency,B-Reason,O,O,O,O,O,B-Drug,B-Strength,I-Strength,B-Route,B-Frequency,I-Frequency,I-Frequency,B-Reason,O,O,B-Drug,B-Strength,I-Strength,B-Route,B-Frequency,I-Frequency,I-Frequency,B-Reason,O,O,B-Drug,O,O,O,O,O,O,B-Strength,I-Strength,B-Route,B-Frequency,O,O,B-Drug,B-Dosage,B-Form,B-Route,B-Frequency,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Route,B-Frequency,O,O,B-Duration,I-Duration,O,O,O,O,O,O,B-Drug,I-Drug,B-Form,B-Dosage,B-Form,B-Route,B-Frequency,O,O,B-Drug,B-Strength,I-Strength,B-Route,B-Frequency,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,O,B-Form,O,B-Strength,I-Strength,B-Route,B-Frequency,O,O,B-Drug,I-Drug,B-Strength,I-Strength,B-Route,B-Frequency,I-Frequency,I-Frequency,B-Reason,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,I-Drug,B-Strength,O,B-Form,B-Dosage,B-Form,B-Route,B-Frequency,B-Reason,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Drug,O,O,O,B-Duration,I-Duration,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-Duration,I-Duration,I-Duration,O,B-Drug,O,O,B-Reason,I-Reason,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_test.rename(columns={'sentence': 'text', 'word_labels': 'labes'}, inplace=True)"
      ],
      "metadata": {
        "id": "e-DKedVnFi8q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# data_train.to_csv('/content/drive/MyDrive/266_final/data/lf_train.csv')\n",
        "# # data_test.to_csv('/content/drive/MyDrive/266_final/data/lf_test.csv')\n",
        "\n",
        "\n",
        "# data_train = pd.read_csv()"
      ],
      "metadata": {
        "id": "rZUaV-UrJAus"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### It looks reasonable, let's proceed with training"
      ],
      "metadata": {
        "id": "oIRanj57PpZu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wm5j6JLfJVS0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n",
        "# import os\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8pmcdPWk_k5H"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\", add_prefix_space=True)\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"yikuan8/Clinical-Longformer\", num_labels=len(labels_to_ids), gradient_checkpointing=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNvJkxlLRZ6n",
        "outputId": "5550fe89-eac5-4065-caf7-2d3c227f9e63"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of LongformerForTokenClassification were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n",
        "# import os\n",
        "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "# model_name = \"emilyalsentzer/Bio_ClinicalBERT\"  # Bio_ClinicalBERT model identifier\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(labels_to_ids))"
      ],
      "metadata": {
        "id": "wjoXu_EoD1O_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 2048\n",
        "TRAIN_BATCH_SIZE = 1\n",
        "VALID_BATCH_SIZE = 1\n",
        "TEST_BATCH_SIZE = 2\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "id": "VRjrBQAR9-zc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "  def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        # step 1: get the sentence and word labels\n",
        "        sentence = self.data.sentence[index].strip().split()\n",
        "        word_labels = self.data.word_labels[index].split(\",\")\n",
        "\n",
        "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
        "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
        "        encoding = self.tokenizer(sentence,\n",
        "                             return_offsets_mapping=True,\n",
        "                             padding='max_length',\n",
        "                             is_split_into_words=True,\n",
        "                             truncation=True,\n",
        "                             max_length=self.max_len,\n",
        "                            #  add_prefix_space=True\n",
        "                            )\n",
        "\n",
        "        # step 3: create token labels only for first word pieces of each tokenized word\n",
        "        labels = [labels_to_ids[label] for label in word_labels]\n",
        "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
        "        # create an empty array of -100 of length max_length\n",
        "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
        "\n",
        "        # set only labels whose first offset position is 0 and the second is not 0\n",
        "        i = 0\n",
        "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
        "          if mapping[0] == 0 and mapping[1] != 0:\n",
        "            # overwrite label\n",
        "            encoded_labels[idx] = labels[i]\n",
        "            i += 1\n",
        "\n",
        "        # step 4: turn everything into PyTorch tensors\n",
        "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.as_tensor(encoded_labels)\n",
        "\n",
        "        return item\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "rYVPN8o4ve9Q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.8\n",
        "train_dataset = data_train.sample(frac=train_size,random_state=200)\n",
        "val_dataset = data_train.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data_train.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"Val Dataset: {}\".format(val_dataset.shape))\n",
        "print(\"Test Dataset: {}\".format(data_test.shape))\n",
        "\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "val_set = dataset(val_dataset, tokenizer, MAX_LEN)\n",
        "test_set = dataset(data_test.reset_index(drop=True), tokenizer, MAX_LEN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDFvMkzgQjUX",
        "outputId": "b659a4c9-ee3c-4195-b605-7c6055910922"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (303, 2)\n",
            "TRAIN Dataset: (242, 2)\n",
            "Val Dataset: (61, 2)\n",
            "Test Dataset: (202, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.to_csv('/content/drive/MyDrive/266_final/data/train.csv', index=False)\n",
        "val_dataset.to_csv('/content/drive/MyDrive/266_final/data/val.csv', index=False)\n"
      ],
      "metadata": {
        "id": "8kKlOcNUpo8S"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Zb6f0F0Ru3",
        "outputId": "c3f44051-182d-482e-96c3-1a603c959828"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    0, 18032, 10566,  ..., 17844, 26056,     2]),\n",
              " 'attention_mask': tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
              " 'offset_mapping': tensor([[0, 0],\n",
              "         [0, 9],\n",
              "         [0, 4],\n",
              "         ...,\n",
              "         [0, 2],\n",
              "         [0, 4],\n",
              "         [0, 0]]),\n",
              " 'labels': tensor([-100,   18,   18,  ...,   17,    4, -100])}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reyjdAMAyFAl",
        "outputId": "d032addb-16fd-4680-dac4-6a548398b0bf"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    0, 18032, 10566,  ...,    79,  2226,     2]),\n",
              " 'attention_mask': tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
              " 'offset_mapping': tensor([[0, 0],\n",
              "         [0, 9],\n",
              "         [0, 4],\n",
              "         ...,\n",
              "         [0, 3],\n",
              "         [0, 9],\n",
              "         [0, 0]]),\n",
              " 'labels': tensor([-100,   18,   18,  ...,   18,   18, -100])}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
        "#   print('{0:10}  {1}'.format(token, label))"
      ],
      "metadata": {
        "id": "f4v9CdAR3b9b"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for token, label in zip(tokenizer.convert_ids_to_tokens(test_set[0][\"input_ids\"]), test_set[0][\"labels\"]):\n",
        "#   print('{0:10}  {1}'.format(token, label))"
      ],
      "metadata": {
        "id": "zjS39K3yyO0i"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "val_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)\n",
        "testing_loader = DataLoader(test_set, **test_params)\n",
        "\n"
      ],
      "metadata": {
        "id": "zDNfrhJP4llk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkNhlqUI43pt",
        "outputId": "fc9bbb9c-4586-4032-c1b0-6feb1e05db30"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LongformerForTokenClassification(\n",
              "  (longformer): LongformerModel(\n",
              "    (embeddings): LongformerEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
              "    )\n",
              "    (encoder): LongformerEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): LongformerSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LongformerIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LongformerOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = training_set[2]\n",
        "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
        "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
        "labels = inputs[\"labels\"].unsqueeze(0)\n",
        "\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUh5g2Az5J7u",
        "outputId": "e53a3f20-a6b1-4299-a0a4-0796e3ffda97"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.7948, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-qfx9lU6JqM",
        "outputId": "58ff984a-2aca-4c1a-bc73-0632807307b4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2048, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE, )"
      ],
      "metadata": {
        "id": "CaOtXFnGQgqz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def focal_loss(logits, labels, alpha=0.25, gamma=2.0, ignore_index=-100):\n",
        "    \"\"\"\n",
        "    logits: [batch_size, seq_len, num_labels] - model predictions\n",
        "    labels: [batch_size, seq_len] - ground truth labels\n",
        "    \"\"\"\n",
        "    # Calculate Cross Entropy Loss without reduction\n",
        "    ce_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1), reduction='none', ignore_index=ignore_index)\n",
        "\n",
        "    # Get the predictions\n",
        "    pred_probs = F.softmax(logits.view(-1, logits.size(-1)), dim=-1)\n",
        "    pred_class = labels.view(-1)\n",
        "\n",
        "    # focusing parameter\n",
        "    gamma = gamma\n",
        "\n",
        "    # Filter out 'ignore_index' labels\n",
        "    filtered = labels.view(-1) != ignore_index\n",
        "\n",
        "    # Calculate focal loss\n",
        "    ce_loss_filtered = ce_loss[filtered]\n",
        "    pred_probs_filtered = pred_probs[filtered]\n",
        "    pred_class_filtered = pred_class[filtered]\n",
        "\n",
        "    # Construct the loss\n",
        "    pt = pred_probs_filtered.gather(1, pred_class_filtered.unsqueeze(-1)).squeeze()\n",
        "    loss = ((1 - pt) ** gamma * ce_loss_filtered).mean()  # mean over the batch\n",
        "\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "_247Nj559I5C"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_global_attention_mask_for_ade(tokens, labels):\n",
        "    \"\"\"\n",
        "    Create a global attention mask for tokens identified as related to ADEs.\n",
        "\n",
        "    Args:\n",
        "        tokens (List[str]): List of tokens in the sequence.\n",
        "        labels (List[str]): List of labels for each token, with ADE-related labels clearly marked.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The global attention mask.\n",
        "    \"\"\"\n",
        "    global_attention_mask = torch.zeros(len(tokens))\n",
        "\n",
        "    for idx, label in enumerate(labels):\n",
        "        if label.startswith('B-ADE') or label.startswith('I-ADE'):  # Assuming ADE labels are marked as such\n",
        "            global_attention_mask[idx] = 1\n",
        "\n",
        "    return global_attention_mask"
      ],
      "metadata": {
        "id": "KdacHg9jwE0g"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(epoch):\n",
        "#     tr_loss, tr_accuracy = 0, 0\n",
        "#     nb_tr_steps = 0\n",
        "#     tr_preds, tr_labels = [], []\n",
        "\n",
        "#     model.train()\n",
        "\n",
        "#     for idx, (batch, labels) in enumerate(training_loader):\n",
        "#         ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "#         mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "#         labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "#         # Create a global attention mask with 1s for first token and ADE entity locations\n",
        "#         global_attention_mask = torch.zeros_like(ids)\n",
        "#         global_attention_mask[:, 0] = 1  # Global attention on the first token ([CLS])\n",
        "\n",
        "#         for batch_idx in range(ids.size(0)):  # Loop over batch dimension\n",
        "#             for token_idx in range(ids.size(1)):  # Loop over sequence length\n",
        "#                 # Check if the current token is B-ADE or I-ADE and set global attention if so\n",
        "#                 if labels[batch_idx, token_idx] == labels_to_ids['B-ADE'] or labels[batch_idx, token_idx] == labels_to_ids['I-ADE']:\n",
        "#                     global_attention_mask[batch_idx, token_idx] = 1\n",
        "\n",
        "#         outputs = model(input_ids=ids, attention_mask=mask, global_attention_mask=global_attention_mask.to(device))\n",
        "#         logits = outputs.logits\n",
        "#         loss = focal_loss(logits, labels)  # Implement your focal_loss function\n",
        "\n",
        "#         tr_loss += loss.item()\n",
        "#         nb_tr_steps += 1\n",
        "\n",
        "#         if idx % 100 == 0:\n",
        "#             loss_step = tr_loss / nb_tr_steps\n",
        "#             print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "#         # Assuming implementation for gradient clipping and optimizer step\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "#         optimizer.step()\n",
        "\n",
        "#     print(f\"Training loss epoch: {tr_loss / nb_tr_steps}\")"
      ],
      "metadata": {
        "id": "jLuX49jH4Yz_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "        mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "        labels = batch['labels'].to(device, dtype=torch.long)\n",
        "\n",
        "        # Create a global attention mask with 1s for first token and ADE entity locations\n",
        "        global_attention_mask = torch.zeros_like(ids)\n",
        "        global_attention_mask[:, 0] = 1  # Global attention on the first token ([CLS])\n",
        "\n",
        "        # # Assuming 'labels_to_ids' is a dictionary mapping label strings to their encoded IDs\n",
        "        # b_ade_id = labels_to_ids['B-Drug']\n",
        "        # i_ade_id = labels_to_ids['I-Drug']\n",
        "\n",
        "        # # Find indices where labels are B-ADE or I-ADE\n",
        "        # b_ade_indices = (labels == b_ade_id).nonzero(as_tuple=True)\n",
        "        # i_ade_indices = (labels == i_ade_id).nonzero(as_tuple=True)\n",
        "\n",
        "        # # Apply global attention to B-ADE and I-ADE locations\n",
        "        # # Assuming a 2D structure for `labels`, adjust dimensions as necessary\n",
        "        # for idx in b_ade_indices[0]:\n",
        "        #     global_attention_mask[idx] = 1\n",
        "        # for idx in i_ade_indices[0]:\n",
        "        #     global_attention_mask[idx] = 1\n",
        "\n",
        "        # Perform a forward pass to get the logits\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, global_attention_mask=global_attention_mask)\n",
        "        logits = outputs.logits\n",
        "        # Calculate the loss using focal_loss function directly\n",
        "        loss = focal_loss(logits, labels)  # Assuming focal_loss is correctly implemented elsewhere\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += labels.size(0)\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            loss_step = tr_loss / nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # Decoding the logits to compute accuracy\n",
        "        active_logits = logits.view(-1, model.num_labels)  # Adjust according to your model's output shape\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1)\n",
        "\n",
        "        # Ignoring the predictions of the padding tokens\n",
        "        active_accuracy = labels.view(-1) != -100\n",
        "        active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
        "\n",
        "        labels = torch.masked_select(active_labels, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_labels.extend(labels.cpu().numpy())\n",
        "        tr_preds.extend(predictions.cpu().numpy())\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=MAX_GRAD_NORM)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ],
      "metadata": {
        "id": "V449l7PpdLOK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "hJTCIVnHvK-a"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfgSA5O9-zhm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "id": "i5mSx2WHtyzz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9yYcqE5Qn62",
        "outputId": "fb8a91d0-61e3-41dd-f410-11152f9e1f37"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 2.475255012512207\n",
            "Training loss per 100 training steps: 0.3614272003311037\n",
            "Training loss per 100 training steps: 0.24854684799483315\n",
            "Training loss epoch: 0.21998569088668585\n",
            "Training accuracy epoch: 0.9418938144051487\n",
            "Training epoch: 2\n",
            "Training loss per 100 training steps: 0.1692674458026886\n",
            "Training loss per 100 training steps: 0.07292473481191175\n",
            "Training loss per 100 training steps: 0.06451280263225914\n",
            "Training loss epoch: 0.06167368947967025\n",
            "Training accuracy epoch: 0.9778579885027718\n",
            "Training epoch: 3\n",
            "Training loss per 100 training steps: 0.07445260137319565\n",
            "Training loss per 100 training steps: 0.039080188472497064\n",
            "Training loss per 100 training steps: 0.037626489910467374\n",
            "Training loss epoch: 0.03667426920096171\n",
            "Training accuracy epoch: 0.98333298312044\n",
            "Training epoch: 4\n",
            "Training loss per 100 training steps: 0.0032598497346043587\n",
            "Training loss per 100 training steps: 0.030899977374886447\n",
            "Training loss per 100 training steps: 0.0272147800460335\n",
            "Training loss epoch: 0.026749771419568143\n",
            "Training accuracy epoch: 0.9859450271867407\n",
            "Training epoch: 5\n",
            "Training loss per 100 training steps: 0.011909251101315022\n",
            "Training loss per 100 training steps: 0.02306554979793981\n",
            "Training loss per 100 training steps: 0.020436909913126813\n",
            "Training loss epoch: 0.020952074137974043\n",
            "Training accuracy epoch: 0.9878517933459697\n",
            "Training epoch: 6\n",
            "Training loss per 100 training steps: 0.014602182433009148\n",
            "Training loss per 100 training steps: 0.01771162428680201\n",
            "Training loss per 100 training steps: 0.016651518017351014\n",
            "Training loss epoch: 0.016439858942444402\n",
            "Training accuracy epoch: 0.9895098307255135\n",
            "Training epoch: 7\n",
            "Training loss per 100 training steps: 0.01737895980477333\n",
            "Training loss per 100 training steps: 0.01445964716834052\n",
            "Training loss per 100 training steps: 0.013509364024246144\n",
            "Training loss epoch: 0.01383623140349646\n",
            "Training accuracy epoch: 0.9903351600646031\n",
            "Training epoch: 8\n",
            "Training loss per 100 training steps: 0.0048169600777328014\n",
            "Training loss per 100 training steps: 0.012253778498423271\n",
            "Training loss per 100 training steps: 0.012300915952916842\n",
            "Training loss epoch: 0.011728660244842119\n",
            "Training accuracy epoch: 0.9913202502628036\n",
            "Training epoch: 9\n",
            "Training loss per 100 training steps: 0.0005417625070549548\n",
            "Training loss per 100 training steps: 0.008918478946545275\n",
            "Training loss per 100 training steps: 0.009522572129568307\n",
            "Training loss epoch: 0.009583687325446155\n",
            "Training accuracy epoch: 0.9924515354574098\n",
            "Training epoch: 10\n",
            "Training loss per 100 training steps: 0.020519746467471123\n",
            "Training loss per 100 training steps: 0.008866578886479353\n",
            "Training loss per 100 training steps: 0.008220409614223535\n",
            "Training loss epoch: 0.008104821910970067\n",
            "Training accuracy epoch: 0.9933872322183209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps = 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "            mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "            labels = batch['labels'].to(device, dtype=torch.long)\n",
        "            global_attention_mask = torch.zeros_like(ids)\n",
        "            global_attention_mask[:, 0] = 1  # Apply global attention to the first token\n",
        "\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, global_attention_mask=global_attention_mask)\n",
        "            loss = focal_loss(outputs.logits, labels)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "            if idx % 100 == 0:\n",
        "                print(f\"Validation loss per 100 evaluation steps: {eval_loss / nb_eval_steps}\")\n",
        "\n",
        "            active_logits = outputs.logits.view(-1, model.num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
        "            active_accuracy = labels.view(-1) != -100\n",
        "            active_labels = torch.masked_select(labels.view(-1), active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(active_labels.cpu().numpy())\n",
        "            eval_preds.extend(predictions.cpu().numpy())\n",
        "\n",
        "    # Calculate and print final evaluation metrics\n",
        "    eval_accuracy = accuracy_score(eval_labels, eval_preds)\n",
        "    print(f\"Validation Loss: {eval_loss / nb_eval_steps}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    # Optionally return detailed evaluation metrics\n",
        "    return eval_labels, eval_preds\n"
      ],
      "metadata": {
        "id": "-yPKcQuJZR_O"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def valid(model, testing_loader, labels_to_ids):\n",
        "#     model.eval()\n",
        "#     eval_loss, eval_accuracy = 0, 0\n",
        "#     nb_eval_steps = 0\n",
        "#     eval_preds, eval_labels = [], []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for idx, batch in enumerate(testing_loader):\n",
        "#             ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "#             mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "#             labels = batch['labels'].to(device, dtype=torch.long)\n",
        "\n",
        "\n",
        "#             # Initialize global attention mask: all zeros, then set dynamically for ADE tokens\n",
        "#             global_attention_mask = torch.zeros_like(ids)\n",
        "#             global_attention_mask[:, 0] = 1\n",
        "\n",
        "#             # # Dynamically set global attention for B-ADE and I-ADE locations\n",
        "#             # for batch_idx in range(ids.size(0)):  # Loop over batch dimension\n",
        "#             #     for token_idx in range(ids.size(1)):  # Loop over sequence length\n",
        "#             #         label_id = labels[batch_idx, token_idx].item()  # Get the numerical label ID\n",
        "#             #         # Check if the current token is B-ADE or I-ADE and set global attention if so\n",
        "#             #         if label_id == labels_to_ids['B-Drug'] or label_id == labels_to_ids['I-Drug']:\n",
        "#             #             global_attention_mask[batch_idx, token_idx] = 1\n",
        "\n",
        "#             # Perform a forward pass to get the logits\n",
        "#             outputs = model(input_ids=ids, attention_mask=mask, global_attention_mask=global_attention_mask)\n",
        "#             logits = outputs.logits\n",
        "#             loss = focal_loss(logits, labels)  # Assuming focal_loss is correctly implemented elsewhere\n",
        "\n",
        "#             eval_loss += loss.item()\n",
        "#             nb_eval_steps += 1\n",
        "\n",
        "#             if idx % 100 == 0:\n",
        "#                 print(f\"Validation loss per 100 evaluation steps: {eval_loss / nb_eval_steps}\")\n",
        "\n",
        "#             # Decoding the logits to compute accuracy\n",
        "#             active_logits = logits.view(-1, model.num_labels)\n",
        "#             flattened_predictions = torch.argmax(active_logits, axis=1)\n",
        "#             active_accuracy = labels.view(-1) != -100\n",
        "#             active_labels = torch.masked_select(labels.view(-1), active_accuracy)\n",
        "#             predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "#             eval_labels.extend(active_labels.cpu().numpy())\n",
        "#             eval_preds.extend(predictions.cpu().numpy())\n",
        "\n",
        "#     eval_accuracy = accuracy_score(eval_labels, eval_preds)\n",
        "#     print(f\"Validation Loss: {eval_loss / nb_eval_steps}\")\n",
        "#     print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "#     return eval_labels, eval_preds"
      ],
      "metadata": {
        "id": "PGIt_PbW4wOl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, predictions = valid(model, val_loader)\n"
      ],
      "metadata": {
        "id": "jsTZFFHJgHIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc51389-6381-4060-8a62-a77a76697f0d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 0.0052735209465026855\n",
            "Validation Loss: 0.020369224226878493\n",
            "Validation Accuracy: 0.9864398564355864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numerical labels and predictions to their string equivalents\n",
        "string_labels = [ids_to_labels[id] for id in labels]  # Convert every label ID in the list\n",
        "string_predictions = [ids_to_labels[id] for id in predictions]  # Same for predictions\n",
        "\n",
        "# Since `seqeval` expects a list of lists (one per sentence), adjust accordingly\n",
        "# This step assumes each label/prediction is already grouped by sentences\n",
        "string_labels = [string_labels]  # Wrap in another list if you have flat lists\n",
        "string_predictions = [string_predictions]\n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report(string_labels, string_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL5t4Q18-Ig8",
        "outputId": "880f0e40-a016-4097-c124-cbfd61c8bb30"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADE       0.44      0.65      0.53        80\n",
            "      Dosage       0.84      0.84      0.84       190\n",
            "        Drug       0.90      0.92      0.91      1184\n",
            "    Duration       0.70      0.79      0.74        42\n",
            "        Form       0.88      0.86      0.87       197\n",
            "   Frequency       0.70      0.77      0.74       299\n",
            "      Reason       0.48      0.62      0.54       252\n",
            "       Route       0.81      0.79      0.80       255\n",
            "    Strength       0.93      0.96      0.95       358\n",
            "\n",
            "   micro avg       0.80      0.85      0.83      2857\n",
            "   macro avg       0.74      0.80      0.77      2857\n",
            "weighted avg       0.82      0.85      0.83      2857\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels, test_predictions = valid(model, testing_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD-UQ4vC9xhw",
        "outputId": "e6ca4559-fe57-4a55-f7cf-d43518ae7b34"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 0.030953148379921913\n",
            "Validation loss per 100 evaluation steps: 0.01939068721966947\n",
            "Validation Loss: 0.01939068721966947\n",
            "Validation Accuracy: 0.9871641601114471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "id": "51DtBST8iCNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_labels, test_preds = valid(model, testing_loader)"
      ],
      "metadata": {
        "id": "gUcJIRmR5rlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numerical labels and predictions to their string equivalents\n",
        "string_labels = [ids_to_labels[id] for id in test_labels]  # Convert every label ID in the list\n",
        "string_predictions = [ids_to_labels[id] for id in test_predictions]  # Same for predictions\n",
        "\n",
        "# Since `seqeval` expects a list of lists (one per sentence), adjust accordingly\n",
        "# This step assumes each label/prediction is already grouped by sentences\n",
        "string_labels = [string_labels]  # Wrap in another list if you have flat lists\n",
        "string_predictions = [string_predictions]\n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report(string_labels, string_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40IkfZ9CPbuh",
        "outputId": "1f278755-def5-4a3e-cf4c-6d51f2f828e0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADE       0.48      0.58      0.53       266\n",
            "      Dosage       0.83      0.84      0.83       528\n",
            "        Drug       0.90      0.94      0.92      3467\n",
            "    Duration       0.50      0.55      0.52       110\n",
            "        Form       0.87      0.84      0.86       553\n",
            "   Frequency       0.65      0.72      0.68       633\n",
            "      Reason       0.43      0.58      0.50       871\n",
            "       Route       0.88      0.88      0.88       716\n",
            "    Strength       0.91      0.95      0.93       849\n",
            "\n",
            "   micro avg       0.79      0.85      0.82      7993\n",
            "   macro avg       0.72      0.76      0.74      7993\n",
            "weighted avg       0.80      0.85      0.82      7993\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# labels_to_ids"
      ],
      "metadata": {
        "id": "8sPraEgCQDqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# labels_to_ids = {v: k for k, v in ids_to_labels.items()}\n",
        "\n",
        "# # Assuming ADE has a specific numerical ID or label name in `ids_to_labels`\n",
        "# ade_id = labels_to_ids['B-ADE']\n",
        "\n",
        "# # Convert labels and predictions back to IDs if they are not already\n",
        "# true_ids = [labels_to_ids[label] for label in labels]\n",
        "# predicted_ids = [labels_to_ids[prediction] for prediction in predictions]\n",
        "\n",
        "# # Find indices where ADE was the true label but was predicted incorrectly,\n",
        "# # and where ADE was predicted but not the true label\n",
        "# misclassified_as_ade = []\n",
        "# misclassified_not_ade = []\n",
        "# for i, (true, pred) in enumerate(zip(true_ids, predicted_ids)):\n",
        "#     if true == ade_id and true != pred:\n",
        "#         misclassified_not_ade.append(i)\n",
        "#     elif pred == ade_id and true != pred:\n",
        "#         misclassified_as_ade.append(i)\n"
      ],
      "metadata": {
        "id": "xjn9sCDT8tqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# misclassified_not_ade"
      ],
      "metadata": {
        "id": "qAPRppZmRipd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def retrieve_original_sentence(index, dataframe):\n",
        "#     \"\"\"Fetch the original sentence and its word labels based on the index.\"\"\"\n",
        "#     sentence = dataframe.iloc[index]['sentence']\n",
        "#     word_labels = dataframe.iloc[index]['word_labels']\n",
        "#     return sentence, word_labels.split(',')\n"
      ],
      "metadata": {
        "id": "WoiYkvRsQqyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_dataset"
      ],
      "metadata": {
        "id": "6QKbc5ZURPwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming `misclassified_not_ade` and `misclassified_as_ade` are lists of indices from previous steps\n",
        "# for index in misclassified_not_ade[:10]:  # Adjust the range as needed\n",
        "#     sentence, labels = retrieve_original_sentence(index, val_dataset)\n",
        "#     print(f\"Index {index} - Misclassified (Not ADE):\")\n",
        "#     print(\"Sentence:\", sentence)\n",
        "#     print(\"Labels:\", labels)\n",
        "#     print(\"\\n\")\n",
        "\n",
        "# for index in misclassified_as_ade[:10]:  # Adjust the range as needed\n",
        "#     sentence, labels = retrieve_original_sentence(index, val_dataset)\n",
        "#     print(f\"Index {index} - Misclassified (False ADE):\")\n",
        "#     print(\"Sentence:\", sentence)\n",
        "#     print(\"Labels:\", labels)\n",
        "#     print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "7Pt_L6FPQVNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numerical labels and predictions to their string equivalents\n",
        "string_labels = [ids_to_labels[id] for id in labels]  # Convert every label ID in the list\n",
        "string_predictions = [ids_to_labels[id] for id in predictions]  # Same for predictions\n",
        "\n",
        "# Since `seqeval` expects a list of lists (one per sentence), adjust accordingly\n",
        "# This step assumes each label/prediction is already grouped by sentences\n",
        "string_labels = [string_labels]  # Wrap in another list if you have flat lists\n",
        "string_predictions = [string_predictions]\n",
        "\n"
      ],
      "metadata": {
        "id": "UcthIoavzjlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wamddIZtoq5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory = \"/content/drive/MyDrive/266_final/clinical_longformer_final\"\n",
        "\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "tokenizer.save_vocabulary(directory)\n",
        "model.save_pretrained(directory, safe_serialization=True)"
      ],
      "metadata": {
        "id": "SmhHNpaCzni9"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report([test_labels], [test_preds]))"
      ],
      "metadata": {
        "id": "QqpaqDl26o7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDOInmcW3qwe"
      },
      "source": [
        "Resources\n",
        "\n",
        "### https://github.com/lcampillos/Medical-NER/blob/master/bert_ner.ipynb\n",
        "### https://medium.com/analytics-vidhya/bio-tagged-text-to-original-text-99b05da6664"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
